**Introduction:** 
<br>This project was developed as a part of the [Good night moon early literacy program competition](https://www.drivendata.org/competitions/298/). The competition aims to leverage machine learning techniques to evaluate literacy screening exercise audio recordings from children in kindergarten through third grade. The goal is to assist teachers in efficiently and accurately identifying students who require early literacy intervention. Addressing these challenges at the preschool level is crucial, as early literacy development strongly correlates with later academic success.
**Approach:** 
In this project, we leverage state-of-the-art pretrained audio speech recognition models and fine-tune them for our dataset. Specifically, we evaluated OpenAI’s Whisper and Facebook’s wav2vec2 models from the Hugging Face library. A comparative analysis revealed that Whisper outperformed wav2vec2, leading us to adopt it for further experimentation.
Our initial assessment achieved a log loss (performance metric) value at the 50th percentile. However, we quickly identified that fine-tuning alone was insufficient to achieve significant performance improvements. To address this, we designed a custom Audio-Text Concat model, integrating both audio and text-based features for enhanced recognition. Further details regarding this architecture will be discussed in the **Model Development** section.

